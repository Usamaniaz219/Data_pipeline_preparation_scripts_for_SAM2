{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def create_image_mask_pairs(data_dir):\n",
    "    images_dir = os.path.join(data_dir, \"image_tiles_/\")\n",
    "    masks_dir = os.path.join(data_dir, \"mask_tiles_/\")\n",
    "\n",
    "    # Get lists of files\n",
    "    image_files = sorted(os.listdir(images_dir))\n",
    "    mask_files = sorted(os.listdir(masks_dir))\n",
    "\n",
    "    # Find common files (one-to-one correspondence by name)\n",
    "    common_files = set(image_files) & set(mask_files)\n",
    "\n",
    "    # Filter and retain only the common files\n",
    "    image_files = [f for f in image_files if f in common_files]\n",
    "    mask_files = [f for f in mask_files if f in common_files]\n",
    "\n",
    "    # Ensure both lists are sorted to maintain order\n",
    "    image_files.sort()\n",
    "    mask_files.sort()\n",
    "\n",
    "    # Pair images and masks\n",
    "    all_pairs = [\n",
    "        {\"image\": os.path.join(images_dir, file), \"annotation\": os.path.join(masks_dir, file)}\n",
    "        for file in image_files\n",
    "    ]\n",
    "\n",
    "    print(f\"Total valid pairs: {len(all_pairs)}\")\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    train_pairs, test_pairs = train_test_split(all_pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Save training data to 'train_data.txt'\n",
    "    with open(\"train_data.txt\", \"a\") as train_file:\n",
    "        for pair in train_pairs:\n",
    "            train_file.write(f\"'image_path': {pair['image']}, 'annotation_path': {pair['annotation']}\\n\")\n",
    "\n",
    "    # Save testing data to 'test_data.txt'\n",
    "    with open(\"test_data.txt\", \"a\") as test_file:\n",
    "        for pair in test_pairs:\n",
    "            test_file.write(f\"'image_path': {pair['image']}, 'annotation_path': {pair['annotation']}\\n\")\n",
    "\n",
    "    # Optionally, print sizes for verification\n",
    "#     print(f\"Training pairs: {len(train_pairs)}\")\n",
    "#     print(f\"Testing pairs: {len(test_pairs)}\")\n",
    "    \n",
    "    return train_pairs,test_pairs\n",
    "\n",
    "data_dir = \"/media/usama/SSD/Data_for_SAM2_model_Finetuning/Cities/fl_bowling_city/output/image_tiles_and_masks_tiles_for_fl_bowling_city/\"\n",
    "train_pairs,test_pairs = create_image_mask_pairs(data_dir)\n",
    "print(len(train_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "import cv2\n",
    "from shapely.validation import make_valid\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_representative_points_within_contours(contours, contours_1,mask):\n",
    "    \"\"\"Get representative points within each part of the polygon or a reduced number if there's intersection with contours_1.\"\"\"\n",
    "    representative_points = []\n",
    "\n",
    "    def get_quadrant_representative_points(polygon):\n",
    "        \"\"\"Get representative points from the quadrants of a polygon.\"\"\"\n",
    "        min_x, min_y, max_x, max_y = polygon.bounds\n",
    "        center_x = (min_x + max_x) / 2\n",
    "        center_y = (min_y + max_y) / 2\n",
    "\n",
    "        quadrants = [\n",
    "            Polygon([(min_x, min_y), (center_x, min_y), (center_x, center_y), (min_x, center_y)]),\n",
    "            Polygon([(center_x, min_y), (max_x, min_y), (max_x, center_y), (center_x, center_y)]),\n",
    "            Polygon([(min_x, center_y), (center_x, center_y), (center_x, max_y), (min_x, max_y)]),\n",
    "            Polygon([(center_x, center_y), (max_x, center_y), (max_x, max_y), (center_x, max_y)])\n",
    "        ]\n",
    "\n",
    "        temp_points = []  # Temporary list to hold quadrant representative points\n",
    "\n",
    "        for quadrant in quadrants:\n",
    "            if quadrant.intersects(polygon):\n",
    "                intersection = quadrant.intersection(polygon)\n",
    "                if not intersection.is_empty:\n",
    "                    rep_point = intersection.representative_point()\n",
    "                    temp_points.append((rep_point.x, rep_point.y))\n",
    "\n",
    "        return temp_points\n",
    "    \n",
    "    def is_foreground_pixel(x, y, mask):\n",
    "        \"\"\"Check if a point lies on the foreground pixel of the annotation mask.\"\"\"\n",
    "        rows, cols = mask.shape\n",
    "        if 0 <= int(y) < rows and 0 <= int(x) < cols:\n",
    "#             return mask[int(y), int(x)] == 255  # Adjust based on foreground label\n",
    "            return mask[int(y), int(x)]>0\n",
    "        return False\n",
    "\n",
    "    for contour_1 in contours_1:\n",
    "        try:\n",
    "            shapely_polygon = Polygon([(point[0][0], point[0][1]) for point in contour_1])\n",
    "            shapely_polygon = make_valid(shapely_polygon)  # Ensure the polygon is valid\n",
    "            count = 0\n",
    "            tmp_pts = []\n",
    "\n",
    "            for contour in contours:\n",
    "                # shapely_polygon_1 = Polygon([(point[0][0], point[0][1]) for point in contour])\n",
    "                coordinates = []\n",
    "                for cont_point in contour:\n",
    "                    x = cont_point[0][0]\n",
    "                    y = cont_point[0][1]\n",
    "                    coordinates.append((x, y))\n",
    "                tmp_pts_1 =[]\n",
    "                if len(coordinates)>3:\n",
    "                # Create the polygon using the list of coordinates\n",
    "                    shapely_polygon_1 = Polygon(coordinates)\n",
    "                    shapely_polygon_1 = make_valid(shapely_polygon_1)  # Ensure the polygon is valid\n",
    "                    # plot_polygon\n",
    "                 \n",
    "\n",
    "                    if shapely_polygon.intersects(shapely_polygon_1):\n",
    "                        count += 1\n",
    "\n",
    "                        if shapely_polygon_1.area <= 200:\n",
    "                            rep_point = shapely_polygon_1.representative_point()\n",
    "                            representative_points.append(([(rep_point.x, rep_point.y)]))\n",
    "                            print(\"representative point after area is less than 200\",representative_points)\n",
    "                        else:\n",
    "                            pts = get_quadrant_representative_points(shapely_polygon_1)\n",
    "                            # print(\"points11\",points)\n",
    "                            for pt in pts:\n",
    "                                if is_foreground_pixel(pt[0],pt[1],mask):\n",
    "                                    tmp_pts_1.append(pt)\n",
    "                            tmp_pts.append(tmp_pts_1)\n",
    "\n",
    "                            # tmp_pts.append(get_quadrant_representative_points(shapely_polygon_1))\n",
    "\n",
    "            if count > 1:\n",
    "                print(\"length of tmp_pts\",len(tmp_pts))\n",
    "                if len(tmp_pts) >= 2:\n",
    "                    representative_points.append(list(random.sample(tmp_pts[0], 2)))\n",
    "                    representative_points.append(list(random.sample(tmp_pts[1], 2)))\n",
    "                elif tmp_pts:\n",
    "                    representative_points.extend(list(tmp_pts[0]))\n",
    "            elif count==1:\n",
    "#                 rep_point = shapely_polygon.representative_point()\n",
    "#                 representative_points.append((rep_point.x, rep_point.y))  # To tackle the case where intersection is not present\n",
    "                if tmp_pts:\n",
    "                # If no multiple intersections, still get quadrant points\n",
    "                    \n",
    "                    representative_points.append(list(tmp_pts[0]))\n",
    "                    # print(representative_points)\n",
    "            else:\n",
    "                rep_point = shapely_polygon.representative_point()\n",
    "                representative_points.append(list((rep_point.x, rep_point.y)))  # \n",
    "\n",
    "                # if tmp_pts:\n",
    "                    \n",
    "                # # If no multiple intersections, still get quadrant points\n",
    "                #     representative_points.extend(tmp_pts[0])\n",
    "\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Error creating polygon: {e}\")\n",
    "            continue\n",
    "\n",
    "    return representative_points\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def read_batch(data, visualize_data=False):\n",
    "    output_base_dir = \"output\"\n",
    "    images_dir = os.path.join(output_base_dir, \"images\")\n",
    "    masks_dir = os.path.join(output_base_dir, \"masks\")\n",
    "    txt_files_dir = os.path.join(output_base_dir, \"txt_files\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(masks_dir, exist_ok=True)\n",
    "    os.makedirs(txt_files_dir, exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    for ent in data:\n",
    "        image = cv2.imread(ent[\"image\"])[..., ::-1]\n",
    "        ann_map = cv2.imread(ent[\"annotation\"], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None or ann_map is None:\n",
    "            print(f\"Error: Could not read image or mask from path {ent['image']} or {ent['annotation']}\")\n",
    "            continue\n",
    "\n",
    "        scale = min(1024 / image.shape[1], 1024 / image.shape[0])\n",
    "        image = cv2.resize(image, (int(image.shape[1] * scale), int(image.shape[0] * scale)))\n",
    "#         ann_map = cv2.resize(ann_map, (int(ann_map.shape[1] * scale), int(ann_map.shape[0] * scale)), interpolation=cv2.INTER_NEAREST)\n",
    "        ann_map = cv2.resize(ann_map, (int(ann_map.shape[1] * scale), int(ann_map.shape[0] * scale)))\n",
    "        _, binary_mask = cv2.threshold(ann_map, 127, 255, cv2.THRESH_BINARY)\n",
    "        contours_1, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # contours_1_blank_image = np.zeros(image.shape[:2],dtype=np.uint8)\n",
    "#         print(\"Contours length before erosion:\", len(contours_1))\n",
    "        eroded_mask = cv2.erode(ann_map, np.ones((5, 5), np.uint8), iterations=2)\n",
    "        _, binary_mask_eroded = cv2.threshold(eroded_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        contours_2, _ = cv2.findContours(binary_mask_eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # contours_2_blank_image = np.zeros(image.shape[:2],dtype=np.uint8)\n",
    "#         print(\"Contours length after erosion:\", len(contours_2))\n",
    "        final_mask = cv2.erode(ann_map, np.ones((5, 5), np.uint8), iterations=2) if len(contours_2) >= len(contours_1) else ann_map\n",
    "#         for i in range(1, 2):\n",
    "       \n",
    "        _, binary_mask_final = cv2.threshold(final_mask, 100, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(binary_mask_final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         cv2.drawContours(image, contours, -1, (255, 255, 255), 10)  # Green color, thickness of 2\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "        # Get representative points with intersection logic\n",
    "        rep_points = get_representative_points_within_contours(contours, contours_1,ann_map)\n",
    "        print(\"points\",rep_points)\n",
    "#             print(\"length of points\",len(points))\n",
    "#             print(\"points\",points)\n",
    "        \n",
    "        ct = 0\n",
    "        if len(rep_points)!=0:\n",
    "        # if points is not None:  \n",
    "            for rep_points_item in rep_points:\n",
    "                if len(rep_points_item)>=3:\n",
    "                    ct+=1\n",
    "            if ct==len(rep_points):\n",
    "                pts_ = rep_points\n",
    "            else:\n",
    "                continue\n",
    "            for i in range(3):\n",
    "                image_path = ent[\"image\"]\n",
    "                mask_path = ent[\"annotation\"]\n",
    "                image = cv2.imread(image_path)\n",
    "                mask = cv2.imread(mask_path)\n",
    "                copy_image_name  = f\"{os.path.basename(ent['image']).split('.')[0]}_copy{i}.jpg\"\n",
    "                copy_mask_name  = f\"{os.path.basename(ent['annotation']).split('.')[0]}_copy{i}.jpg\"\n",
    "            \n",
    "                copy_image_path = os.path.join(images_dir, copy_image_name)\n",
    "                print(\"copy image path\",copy_image_path)\n",
    "                cv2.imwrite(copy_image_path,image)\n",
    "              \n",
    "\n",
    "                copy_mask_path = os.path.join(masks_dir, copy_mask_name)\n",
    "                cv2.imwrite(copy_mask_path,mask)\n",
    "                \n",
    "                txt_file_name = f'{copy_image_name.split(\".\")[0]}.txt'\n",
    "                copy_txt_path = os.path.join(txt_files_dir, txt_file_name)\n",
    "                \n",
    "                points_pair = []\n",
    "                for pt_element in pts_:\n",
    "                    # Get the i-th point from each element and convert to integer\n",
    "                    pt_ = tuple(map(int, pt_element[i]))  # Convert to integer\n",
    "                    points_pair.append(pt_)\n",
    "                    with open(copy_txt_path, 'w') as file:\n",
    "                        # for point in points:\n",
    "                        for (cX, cY) in points_pair:\n",
    "                            file.write(f'{cX}, {cY}\\n')\n",
    "                print(\"point pairs\",points_pair)\n",
    "#                 if visualize_data:\n",
    "#                     plt.figure(figsize=(10, 10))\n",
    "#                     plt.imshow(ann_map, cmap='gray')\n",
    "#                     for (cX, cY) in points_pair:\n",
    "#                         plt.plot(cX, cY, 'ro')\n",
    "#                     plt.title(f\"Image: {ent['image']} with Contour Points\")\n",
    "#                     plt.show()\n",
    "\n",
    "\n",
    "                results.append({\n",
    "                \"image\": ent[\"image\"],\n",
    "                \"annotation\": ent[\"annotation\"],\n",
    "                \"txt_file\": copy_txt_path,\n",
    "                \"points\": points_pair\n",
    "                    \n",
    "\n",
    "\n",
    "        })\n",
    "                \n",
    "\n",
    "    return results\n",
    "\n",
    "# sk_tiles_/186_tx_willis_147.jpg', 'annotation': '/media/usama/SSD/Data_for_SAM2_model_Finetuning/Cities/tx_willis_city/output/step6_outputs/mask_tiles_/186_tx_willis_147.jpg'}]\n",
    "train_data =   [{'image': '/media/usama/SSD/Data_for_SAM2_model_Finetuning/Cities/ct_sprague_city/output/step6_outputs/image_tiles_/60_ct_sprague_64.jpg', 'annotation': '/media/usama/SSD/Data_for_SAM2_model_Finetuning/Cities/ct_sprague_city/output/step6_outputs/mask_tiles_/60_ct_sprague_64.jpg'}]\n",
    "# es_and_mask_tiles_for_Fl_indialantic_city/image_tiles_/0_indialantic_77.jpg', 'annotation': '/media/usama/SSD/Data_for_SAM2_model_Finetuning/Cities/fl_indialantic_city/output/image_tiles_and_mask_tiles_for_Fl_indialantic_city/mask_tiles_/0_indialantic_77.jpg'}]\n",
    "results = read_batch(train_pairs, visualize_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
